{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c0731a5-8dd9-422d-a656-b7f06e580112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " 0\n",
      "Logistic Regression: Accuracy = 0.9737\n",
      "Decision Tree: Accuracy = 0.9474\n",
      "Random Forest: Accuracy = 0.9649\n",
      "SVM: Accuracy = 0.9737\n",
      "k-NN: Accuracy = 0.9474\n",
      "\n",
      "‚úÖ Best Performing Model: Logistic Regression (0.9737)\n",
      "‚ùå Worst Performing Model: Decision Tree (0.9474)\n",
      "\n",
      "Classification Report (Best Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Breast Cancer Classification Assignment\n",
    "\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£ Load and Preprocess the Breast Cancer Dataset\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name=\"target\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", X.isnull().sum().sum())\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# üîç Preprocessing Explanation:\n",
    "# - Checked for missing values (none found)\n",
    "# - Standardized features using StandardScaler to ensure all values are on the same scale\n",
    "\n",
    "# 2Ô∏è‚É£ Classification Algorithms\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# 1. Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "results['Logistic Regression'] = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# 2. Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "results['Decision Tree'] = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "# 3. Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "results['Random Forest'] = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# 4. Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "results['SVM'] = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# 5. k-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "results['k-NN'] = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "# 3Ô∏è‚É£ Model Comparison\n",
    "\n",
    "# Print model accuracies\n",
    "for model, acc in results.items():\n",
    "    print(f\"{model}: Accuracy = {acc:.4f}\")\n",
    "\n",
    "# Identify best and worst performing models\n",
    "best_model = max(results, key=results.get)\n",
    "worst_model = min(results, key=results.get)\n",
    "\n",
    "print(f\"\\n‚úÖ Best Performing Model: {best_model} ({results[best_model]:.4f})\")\n",
    "print(f\"‚ùå Worst Performing Model: {worst_model} ({results[worst_model]:.4f})\")\n",
    "\n",
    "# 4Ô∏è‚É£ Summary\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report (Best Model):\")\n",
    "if best_model == \"Logistic Regression\":\n",
    "    print(classification_report(y_test, y_pred_lr))\n",
    "elif best_model == \"Decision Tree\":\n",
    "    print(classification_report(y_test, y_pred_dt))\n",
    "elif best_model == \"Random Forest\":\n",
    "    print(classification_report(y_test, y_pred_rf))\n",
    "elif best_model == \"SVM\":\n",
    "    print(classification_report(y_test, y_pred_svm))\n",
    "else:\n",
    "    print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba317779-ae63-49ff-b147-bd43c3f8815f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
